{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import operator\n",
    "from statistics import mode\n",
    "from utils_video import preprocess_input\n",
    "from utils_video import get_labels\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from math import ceil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras_ssd512 import ssd_512\n",
    "from keras_ssd_loss import SSDLoss\n",
    "from ssd_box_encode_decode_utils import SSDBoxEncoder, decode_y, decode_y2\n",
    "from ssd_batch_generator import BatchGenerator\n",
    "from utils import draw_axis, plot_pose_cube\n",
    "\n",
    "import tensorflow as tf  \n",
    "import keras.backend.tensorflow_backend as KTF  \n",
    "import os\n",
    "# 设置可见GPU\n",
    "gpu_no = '1'  # or '1'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_no\n",
    "#定义TensorFlow配置\n",
    "config = tf.ConfigProto()\n",
    "#配置GPU内存分配方式\n",
    "config.gpu_options.allow_growth = True\n",
    "KTF.set_session(tf.Session(config=config))  \n",
    "\n",
    "\n",
    "### Set up the model\n",
    "\n",
    "# 1: Set some necessary parameters\n",
    "\n",
    "img_height = 450 # Height of the input images\n",
    "img_width = 450 # Width of the input images\n",
    "img_channels = 3 # Number of color channels of the input images\n",
    "n_classes = 2 # Number of classes including the background class, e.g. 21 for the Pascal VOC datasets\n",
    "\n",
    "scales=[0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05], # The scales for MS COCO are [0.04, 0.1, 0.26, 0.42, 0.58, 0.74, 0.9, 1.06]\n",
    "aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                         [1.0, 2.0, 0.5],\n",
    "                         [1.0, 2.0, 0.5]]\n",
    "two_boxes_for_ar1 = True\n",
    "limit_boxes = False # Whether or not you want to limit the anchor boxes to lie entirely within the image boundaries\n",
    "variances = [0.1, 0.1, 0.2, 0.2] # The variances by which the encoded target coordinates are scaled as in the original implementation\n",
    "coords = 'centroids' # Whether the box coordinates to be used as targets for the model should be in the 'centroids' or 'minmax' format, see documentation\n",
    "normalize_coords = True\n",
    "\n",
    "# 2: Build the Keras model (and possibly load some trained weights)\n",
    "\n",
    "K.clear_session() # Clear previous models from memory.\n",
    "# The output `predictor_sizes` is needed below to set up `SSDBoxEncoder`\n",
    "model, predictor_sizes = ssd_512(image_size=(img_height, img_width, 3),\n",
    "                n_classes=n_classes,\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.07, 0.15, 0.3, 0.45, 0.6, 0.75, 0.9, 1.05], # The scales for MS COCO are [0.04, 0.1, 0.26, 0.42, 0.58, 0.74, 0.9, 1.06]\n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "               two_boxes_for_ar1=True,\n",
    "#                steps=[8, 16, 32, 64, 128, 256, 512],\n",
    "#                offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "               variances=[0.1, 0.1, 0.2, 0.2],\n",
    "               limit_boxes=False,\n",
    "               coords='centroids',\n",
    "               normalize_coords=True)\n",
    "model.load_weights('./ssd512_0_weights3.h5', by_name=True) # You should load pre-trained weights for the modified VGG-16 base network here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-20756dc75645>, line 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-20756dc75645>\"\u001b[0;36m, line \u001b[0;32m57\u001b[0m\n\u001b[0;31m    img = plot_pose_cube(img, (float(box[3])*3.1415?9-3.14159/2)/3.14159*180, (float(box[2])*3.14159-3.14159/2)/3.14159*180, (float(box[4])*3.14159-3.14159/2)/3.14159*180, tdx = box[5] + (box[6]-box[5])/2, tdy= box[7] + (box[8]-box[7])/2, size=60)\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# video \n",
    "video_capture = cv2.VideoCapture('output1.avi')\n",
    "# font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "cv2.namedWindow('window_frame')\n",
    "# video_capture.set(cv2.CAP_PROP_FRAME_WIDTH, 384);  \n",
    "# video_capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 288);  \n",
    "\n",
    "i = 0\n",
    "c = 0\n",
    "\n",
    "while True:\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    ret, frame = video_capture.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     print(frame.shape)\n",
    "    \n",
    "    frame1 = cv2.resize(frame,(450,450))\n",
    "    \n",
    "    images.append(frame1)\n",
    "#     X = np.array(frame1[np.newaxis, :])\n",
    "    images = np.array(images)\n",
    "    time_start=time.time()\n",
    "\n",
    "\n",
    "    y_pred = model.predict(images)\n",
    "    # 4: Decode the raw prediction `y_pred`\n",
    "    y_pred_decoded = decode_y2(y_pred,\n",
    "                               confidence_thresh=0.99,\n",
    "                              iou_threshold=0.2,\n",
    "                              top_k='all',\n",
    "                              input_coords='centroids',\n",
    "                              normalize_coords=True,\n",
    "                              img_height=450,\n",
    "                              img_width=450)\n",
    "\n",
    "    time_end=time.time()\n",
    "    print('totally cost',time_end-time_start)\n",
    "    # 5: Draw the predicted boxes onto the image\n",
    "#     plt.figure(figsize=(20,12))\n",
    "#     plt.subplot(16, 1, ind+1)\n",
    "#     current_axis = plt.gca()\n",
    "#     print(len(y_pred_decoded[0]))\n",
    "    if len(y_pred_decoded[0]) > 0:\n",
    "    \n",
    "        # Draw the predicted boxes in blue\n",
    "        for box in y_pred_decoded[0]:\n",
    "            label = '{:.3f}: {:.3f}: {:.3f}'.format(float(box[2]), box[3],box[4])\n",
    "#             print(label)\n",
    "            img = cv2.rectangle(images[i],(int(box[5]), int(box[7])), (int(box[6]), int(box[8])), (0,0,255), 2)\n",
    "#             img = draw_axis(img, float(box[3]), float(box[2]), float(box[4]), tdx = box[5] + (box[6]-box[5])/2, tdy= box[7] + (box[8]-box[7])/2, size=50)\n",
    "#             img = draw_axis(img, (float(box[3])*3.14159-3.14159/2)/3.14159*180, (float(box[2])*3.14159-3.14159/2)/3.14159*180, (float(box[4])*3.14159-3.14159/2)/3.14159*180, tdx = box[5] + (box[6]-box[5])/2, tdy= box[7] + (box[8]-box[7])/2, size=80)    \n",
    "#         img = plot_pose_cube(img, (float(box[3])*3.1415?9-3.14159/2)/3.14159*180, (float(box[2])*3.14159-3.14159/2)/3.14159*180, (float(box[4])*3.14159-3.14159/2)/3.14159*180, tdx = box[5] + (box[6]-box[5])/2, tdy= box[7] + (box[8]-box[7])/2, size=60)    \n",
    "        img = plot_pose_cube(img, float(box[3]), float(box[2]), float(box[4])+10, tdx = box[5] + (box[6]-box[5])/2, tdy= box[7] + (box[8]-box[7])/2, size=80)\n",
    "    #         img = plot_pose_cube(img, float(box[3])*100, float(box[2])*100, 0, tdx = box[4] + (box[5]-box[4])/2, tdy= box[6] + (box[7]-box[6])/2, size=80)\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        img = images[i]\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "#         cv2.imshow('window_frame', img)\n",
    "        cv2.imwrite('./videoPics/image'+str(c) + '.jpg', img)\n",
    "        c = c+ 1\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
